{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Skip notebook test\n",
    "-----\n",
    "\n",
    "#### NOTE:  This notebook will take hours to run.\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparing NetworkX vs cuGraph using synthetic data on various algorithms\n",
    "\n",
    "\n",
    "This notebook compares the execution times of many of the cuGraph and NetworkX algorithms when run against identical synthetic data at multiple scales.\n",
    "\n",
    "This notebook uses the RMAT data generator which allows the creation of graphs at various scales.  The notebook, by default, runs on a set of selected sizes but users are free to change or add to that list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Credits\n",
    "\n",
    "    \n",
    "| Author        |    Date    |  Update             | cuGraph Version |  Test Hardware         |\n",
    "| --------------|------------|---------------------|-----------------|------------------------|\n",
    "| Don Acosta    | 1/12/2023  | Created             | 23.02 nightly   | RTX A6000, CUDA 11.7   |\n",
    "| Brad Rees     | 1/27/2023  | Modified            | 23.02 nightly   | RTX A6000, CUDA 11.7   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the overall workflow, NetworkX and cuGraph do things differently.  For example, NetworkX spends a lot of time creating the graph data structure.  cuGraph on the other hand does a lazy creation of the data structure when an algorithm is called.  To further complicate the comparison problem, NetworkX does not always return the answer.  In some cases, it returns a generator that is then called to produce the data.  \n",
    "\n",
    "This benchmark produces two performance metrics:\n",
    " - (1)\tJust the algorithm run time \n",
    " - (2)\tThe algorithm plus graph creation time\n",
    "\n",
    "Since GPU memory is a precious resource, having a lot of temporary data laying around is avoided.  So once a graph is created, the raw data is dropped.  \n",
    " \n",
    "__What is not timed__:  Generating the data with R-MAT</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm (3) run any generators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "|        Algorithm        |  Type         | Undirected Graph | Directed Graph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| Katz                    | Centrality    |   X   |         | \n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| Core Number             | Core          |   X   |         |\n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit\n",
    "| SSSP                    | Traversal     |   X   |         | \n",
    "\n",
    "\n",
    "### Test Data\n",
    "Data is generated using a Recursive MATrix (R-MAT) graph generation algorithm. \n",
    "The generator specifics are documented [here](https://docs.rapids.ai/api/cugraph/stable/api_docs/generator.html)\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "* Running Betweenness Centrality on the full graph is prohibitive using NetworkX.  Anything over k=100 can explode runtime to days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "# to parallelize with dask\n",
    "import dask_cudf\n",
    "from cugraph.dask.common.mg_utils import get_visible_devices\n",
    "from cugraph.testing.mg_utils import start_dask_client, stop_dask_client\n",
    "\n",
    "# NetworkX libraries\n",
    "import networkx as nx\n",
    "\n",
    "# RMAT data generator\n",
    "from cugraph.generators import rmat\n",
    "from cugraph.structure import NumberMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the scale of the test data\n",
    "RMAT generates graph where the number of vertices is a power of 2 and the number of edges is based on an edge factor times the number vertices.\n",
    "\n",
    "Since RMAT tends to generate about 50% isolated vertices, those vertices are dropped from the graph data.  Hence the number of vertices is closer to (2 ** scale) / 2\n",
    "\n",
    "\n",
    "| Scale | Vertices (est) | Edges  |\n",
    "| ------|----------------|--------|\n",
    "| 10 | 512 | 16,384 | \n",
    "| 11 | 1,024 | 32,768| \n",
    "| 12 | 2,048 | 65,536| \n",
    "| 13 | 4,096 | 131,072| \n",
    "| 14 | 8,192 | 262,144| \n",
    "| 15 | 16,384 | 524,288 | \n",
    "| 16 | 32,768 | 1,048,576 | \n",
    "| 17 | 65,536 | 2,097,152 | \n",
    "| 18 | 131,072 | 4,194,304 | \n",
    "| 19 | 262,144 | 8,388,608 | \n",
    "| 20 | 524,288 | 16,777,216 | \n",
    "| 21 | 1,048,576 | 33,554,432 | \n",
    "| 22 | 2,097,152 | 67,108,864 | \n",
    "| 23 | 4,194,304 | 134,217,728 | \n",
    "| 24 | 8,388,608 | 268,435,456 | \n",
    "| 25 | 16,777,216 | 536,870,912 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Sizes\n",
    "# Here you can create an array of test data sizes.   Then set the \"data\" variable to the array you want\n",
    "# the dictionary format is 'name' : scale\n",
    "\n",
    "\n",
    "# These scales are used by R-MAT to determine the number of vertices/edges in the synthetic data graph.\n",
    "data_full = {\n",
    "    'data_scale_10'   :  10,\n",
    "    'data_scale_12'   :  12,\n",
    "    'data_scale_14'  :   14,\n",
    "    'data_scale_16'  :   16,\n",
    "    'data_scale_18'  :   18,\n",
    "    'data_scale_20'  :   20,\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "   'data_scale_9' : 9,\n",
    "   'data_scale_10' : 10,\n",
    "   'data_scale_11' : 11,\n",
    "}\n",
    "\n",
    "\n",
    "# Which dataset is to be used\n",
    "data = data_quick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "The data is generated once for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator \n",
    "#  The result is an edgelist of the size determined by the scale and edge factor\n",
    "def generate_data(scale, edgefactor=16, mg=False):\n",
    "    _gdf = rmat(\n",
    "        scale,\n",
    "        (2 ** scale) * edgefactor,\n",
    "        0.57,\n",
    "        0.19,\n",
    "        0.19,\n",
    "        42,\n",
    "        clip_and_flip=False,\n",
    "        scramble_vertex_ids=True,\n",
    "        create_using=None,  # return edgelist instead of Graph instance\n",
    "        mg=mg # determines whether generated data will be used on one or multiple GPUs\n",
    "        )\n",
    "\n",
    "    clean_coo = NumberMap.renumber(_gdf, src_col_names=\"src\", dst_col_names=\"dst\")[0]\n",
    "    if mg:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"})\n",
    "    else:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"}, inplace=True)\n",
    "\n",
    "    print(f'Generated a dataframe of type {type(clean_coo)}, with {len(clean_coo)} edges')\n",
    "    \n",
    "    return clean_coo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - calls to create_nx_digraph, create_cu_directed_graph.\n",
    "* Undirected Graphs - calls to create_xx_ugraph <- fully symmeterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "def create_nx_graph(_df, directed=False):\n",
    "    t1 = perf_counter()\n",
    "    if directed:\n",
    "        g_type = nx.DiGraph\n",
    "    else:\n",
    "        g_type = nx.Graph\n",
    "        \n",
    "    _gnx = nx.from_pandas_edgelist(_df,\n",
    "                            source='src',\n",
    "                            target='dst',\n",
    "                            edge_attr=None,\n",
    "                            create_using=g_type)\n",
    "    t2 = perf_counter() - t1\n",
    "\n",
    "    return _gnx, t2\n",
    "\n",
    "# cuGraph\n",
    "def create_cu_graph(_df,transpose=False, directed=False, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    _g = cugraph.Graph(directed=directed)\n",
    "\n",
    "    if mg:\n",
    "        # Set the number of partition to #GPUs\n",
    "        npartitions = len(get_visible_devices())\n",
    "        _ddf = dask_cudf.from_cudf(_df.compute(), npartitions=npartitions)\n",
    "        _g.from_dask_cudf_edgelist(_ddf, source=\"src\", destination=\"dst\", edge_attr=None)\n",
    "    else:\n",
    "        _g.from_cudf_edgelist(_df,\n",
    "                            source='src',\n",
    "                            destination='dst',\n",
    "                            edge_attr=None,\n",
    "                            renumber=False,\n",
    "                            store_transposed=transpose)\n",
    "    t2 = perf_counter() - t1\n",
    "\n",
    "    return _g, t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_katz(_G, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _ = nx.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz(_G, alpha, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.katz_centrality(_G, alpha)\n",
    "    else:\n",
    "\n",
    "        _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bc(_G, _k):\n",
    "    t1 = perf_counter()\n",
    "    _ = nx.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc(_G, _k, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.betweenness_centrality(_G, k=_k)\n",
    "    else:   \n",
    "        _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_louvain(_G):\n",
    "    t1 = perf_counter()\n",
    "    parts = community.best_partition(_G)\n",
    "    \n",
    "    # Calculating modularity scores for comparison\n",
    "    _ = community.modularity(parts, _G)\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _, modularity = cugraph.dask.louvain(_G)\n",
    "        print (f'modularity: {modularity}')\n",
    "    else:\n",
    "        _,_ = cugraph.louvain(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_tc(_G):\n",
    "    t1 = perf_counter()\n",
    "    nx_count = nx.triangles(_G)\n",
    "\n",
    "    # To get the number of triangles, we would need to loop through the array and add up each count\n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.triangle_count(_G)\n",
    "    else:\n",
    "        _ = cugraph.triangle_count(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_core_num(_G):\n",
    "    t1 = perf_counter()\n",
    "    _G.remove_edges_from(nx.selfloop_edges(_G))\n",
    "    nx_count = nx.core_number(_G)\n",
    "    \n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.core_number(_G)\n",
    "    else:\n",
    "        _ = cugraph.core_number(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_pagerank(_G):\n",
    "    t1 = perf_counter()\n",
    "    _ = nx.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2 \n",
    "\n",
    "def cu_pagerank(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.pagerank(_G)\n",
    "    else:\n",
    "        _ = cugraph.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_jaccard(_G):\n",
    "    t1 = perf_counter()\n",
    "    nj = nx.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.jaccard(_G)\n",
    "    else:\n",
    "        _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bfs(_G):\n",
    "    seed = 0\n",
    "    t1 = perf_counter()\n",
    "    nb = nx.bfs_edges(_G, seed)\n",
    "    nb_list = list(nb) # gen -> list\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs(_G, mg=False):\n",
    "    seed = 0\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.bfs(_G, seed)\n",
    "    else:\n",
    "        _ = cugraph.bfs(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_sssp(_G):\n",
    "    seed = 0\n",
    "    t1 = perf_counter()\n",
    "    _ = nx.shortest_path(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp(_G, mg=False):\n",
    "    seed = 0\n",
    "    t1 = perf_counter()\n",
    "    # SSSP requires weighted graph\n",
    "    if mg:\n",
    "        _ = cugraph.dask.bfs(_G, seed)\n",
    "    else:\n",
    "        _ = cugraph.bfs(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets\n",
    "num_datasets = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating Graph of Scale = 9\n",
      "Generated a dataframe of type <class 'cudf.core.dataframe.DataFrame'>, with 8192 edges\n",
      "\tdata in gdf 8192 and data in pandas 8192\n",
      "\tKatz  n.c.\n",
      "\tBC k=100  n.c."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/centrality/katz_centrality.py:121: UserWarning: Katz centrality expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\tLouvain  n.c. \n",
      "\tTC  n.c. \n",
      "\tCore Number  n.c. \n",
      "\tPageRank  n.c. \n",
      "\tJaccard  n.c. \n",
      "\tBFS  n.c. \n",
      "\tSSSP  n.c. \n",
      "------------------------------\n",
      "Creating Graph of Scale = 10\n",
      "Generated a dataframe of type <class 'cudf.core.dataframe.DataFrame'>, with 16384 edges\n",
      "\tdata in gdf 16384 and data in pandas 16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/link_analysis/pagerank.py:227: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKatz  n.c.\n",
      "\tBC k=100  n."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/centrality/katz_centrality.py:121: UserWarning: Katz centrality expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c. \n",
      "\tLouvain  n.c. \n",
      "\tTC  n.c. \n",
      "\tCore Number  n.c. \n",
      "\tPageRank  n.c. \n",
      "\tJaccard  n.c. \n",
      "\tBFS  n.c. \n",
      "\tSSSP  n.c. \n",
      "------------------------------\n",
      "Creating Graph of Scale = 11\n",
      "Generated a dataframe of type <class 'cudf.core.dataframe.DataFrame'>, with 32768 edges\n",
      "\tdata in gdf 32768 and data in pandas 32768\n",
      "\tKatz  n."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/link_analysis/pagerank.py:227: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.\n",
      "\tBC k=100  n."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/centrality/katz_centrality.py:121: UserWarning: Katz centrality expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c. \n",
      "\tLouvain  n.c. \n",
      "\tTC  n.c. \n",
      "\tCore Number  n.c. \n",
      "\tPageRank  n.c. \n",
      "\tJaccard  n.c. \n",
      "\tBFS  n.c. \n",
      "\tSSSP  n.c. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/link_analysis/pagerank.py:227: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "algos = []\n",
    "graph_create_cu = []\n",
    "graph_create_nx = []\n",
    "\n",
    "# Two dimension data [file, perf]\n",
    "time_algo_nx = []          # NetworkX\n",
    "time_algo_cu = []          # cuGraph\n",
    "perf = []\n",
    "perf_algo = []\n",
    "\n",
    "algos.append(\"   \")\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    # init all the 2-d arrays\n",
    "    time_algo_nx.append([])\n",
    "    time_algo_cu.append([])\n",
    "    perf.append([])\n",
    "    perf_algo.append([])\n",
    "\n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # generate data\n",
    "    print(\"------------------------------\")\n",
    "    print(f'Creating Graph of Scale = {v}')\n",
    "\n",
    "    gdf = generate_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # create the graphs\n",
    "    g_cu, tcu = create_cu_graph(gdf)\n",
    "    g_nx, tnx = create_nx_graph(pdf)\n",
    "    graph_create_cu.append(tcu)\n",
    "    graph_create_nx.append(tnx)\n",
    "    del gdf, pdf\n",
    "\n",
    "    # prep\n",
    "    deg = g_cu.degree()\n",
    "    deg_max = deg['degree'].max()\n",
    "\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = g_cu.number_of_vertices()\n",
    "\n",
    "    del deg\n",
    "    gc.collect()\n",
    "\n",
    "    #----- Algorithm order is same as defined at top ----\n",
    "\n",
    "    #-- Katz \n",
    "    print(\"\\tKatz  \", end = '')\n",
    "    if i == 0: \n",
    "        algos.append(\"Katz\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_katz(g_nx, alpha)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_katz(g_cu, alpha)\n",
    "    print(\"\")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- BC\n",
    "    print(\"\\tBC k=100  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BC Estimate fixed\")\n",
    "\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = int(num_nodes)\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bc(g_nx, k)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bc(g_cu, k)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- Louvain\n",
    "    print(\"\\tLouvain  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Louvain\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_louvain(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_louvain(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- TC\n",
    "    print(\"\\tTC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"TC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_tc(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_tc(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- Core Number\n",
    "    print(\"\\tCore Number  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Core Number\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_core_num(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_core_num(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- PageRank\n",
    "    print(\"\\tPageRank  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"PageRank\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_pagerank(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_pagerank(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- Jaccard\n",
    "    print(\"\\tJaccard  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Jaccard\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_jaccard(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_jaccard(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- BFS\n",
    "    print(\"\\tBFS  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BFS\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bfs(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bfs(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    #-- SSSP\n",
    "    print(\"\\tSSSP  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"SSP\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_sssp(g_nx)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_sssp(g_cu)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf_algo[i].append ( (tx/tc) )\n",
    "    perf[i].append( (tx + tnx) /  (tc + tcu) )\n",
    "\n",
    "    # increament count\n",
    "    i = i + 1\n",
    "    \n",
    "    del g_cu, g_nx\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   ', 'Katz', 'BC Estimate fixed', 'Louvain', 'TC', 'Core Number', 'PageRank', 'Jaccard', 'BFS', 'SSP']\n",
      "data_scale_9\n",
      "[0.30174025119666154, 0.5252496066735675, 0.4815963183980694, 0.10059243531734213, 0.06274260384596582, 0.08087691640849742, 0.04259226789052634, 0.04541648848958121, 0.04630903277395244]\n",
      "[10.57018736844198, 1.0236825289491465, 3.4565544669058315, 1.7519735735549575, 0.20360754388242536, 1.996866060869272, 0.017142060522749525, 0.07449551793212239, 0.10215939753145187]\n",
      "data_scale_10\n",
      "[10.422613622706065, 2.2596945327623845, 5.400742833397456, 2.670122216953594, 0.682892670528767, 2.511963848371226, 0.5618378459026585, 1.0027274366915082, 1.0377674050792682]\n",
      "[27.48959075860895, 2.275587863157422, 6.2873877384903345, 3.4689708464108686, 0.3821397055328311, 3.8512864713871493, 0.0005884210429041734, 0.1674301749913076, 0.19472820374933392]\n",
      "data_scale_11\n",
      "[18.597918818212044, 4.662328129832614, 9.282539915015656, 5.826916762148887, 1.2560074010281037, 4.831561094416702, 0.6815771129976337, 1.956713995982869, 2.0017224534087275]\n",
      "[50.381630992178266, 4.706337822317938, 10.371674476982982, 8.016961514792193, 0.7960839977603095, 7.554931432029648, 0.000286892032694886, 0.36503329352194, 0.3936930402823485]\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf[i]}\")\n",
    "    print(f\"{perf_algo[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\tAlgorithm Run times  (NX then cuGraph)\n",
      "\n",
      "['   ', 'Katz', 'BC Estimate fixed', 'Louvain', 'TC', 'Core Number', 'PageRank', 'Jaccard', 'BFS', 'SSP']\n",
      "data_scale_9\n",
      "[0.03168975654989481, 0.11808181460946798, 0.0607406310737133, 0.007159244269132614, 0.003216283395886421, 0.004577603191137314, 0.00012310687452554703, 0.00039636343717575073, 0.0004781009629368782]\n",
      "[0.0029980316758155823, 0.11535003408789635, 0.017572594806551933, 0.004086388275027275, 0.015796484425663948, 0.002292393706738949, 0.007181568071246147, 0.005320634692907333, 0.004679950885474682]\n",
      "data_scale_10\n",
      "[0.07129270676523447, 0.26657472364604473, 0.1288990117609501, 0.01734251156449318, 0.008041061460971832, 0.009121773764491081, 7.294118404388428e-06, 0.0009355107322335243, 0.0010360050946474075]\n",
      "[0.0025934437289834023, 0.11714543215930462, 0.020501202903687954, 0.004999324679374695, 0.021042203530669212, 0.002368500456213951, 0.012396086938679218, 0.005587467923760414, 0.005320262163877487]\n",
      "data_scale_11\n",
      "[0.13116520550101995, 0.5985189070925117, 0.296876666136086, 0.04408951010555029, 0.022953813895583153, 0.018125338479876518, 6.923452019691467e-06, 0.0021516336128115654, 0.0022359658032655716]\n",
      "[0.002603433094918728, 0.1271729590371251, 0.0286237932741642, 0.005499528720974922, 0.02883340697735548, 0.0023991400375962257, 0.024132604710757732, 0.005894348956644535, 0.005679464899003506]\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(\"\\n------------------------------\")\n",
    "print(\"\\tAlgorithm Run times  (NX then cuGraph)\\n\")\n",
    "\n",
    "print(algos)\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{time_algo_nx[i]}\")\n",
    "    print(f\"{time_algo_cu[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example MG runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnaim/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37567 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dask client/cluster created using LocalCUDACluster\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Communicator is already initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setting up cluter\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m setup_objs \u001b[38;5;241m=\u001b[39m \u001b[43mstart_dask_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m gdf \u001b[38;5;241m=\u001b[39m generate_data(\u001b[38;5;241m10\u001b[39m, mg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create graph\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/testing/mg_utils.py:167\u001b[0m, in \u001b[0;36mstart_dask_client\u001b[0;34m(protocol, rmm_async, rmm_pool_size, dask_worker_devices, jit_unspill, worker_class, device_memory_limit)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# FIXME: use proper logging, INFO or DEBUG level\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDask client/cluster created using LocalCUDACluster\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m \u001b[43mComms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp2p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (client, cluster)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_12_new_2/lib/python3.10/site-packages/cugraph/dask/comms/comms.py:158\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(comms, p2p, prows, pcols, partition_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m         __instance \u001b[38;5;241m=\u001b[39m comms\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator is already initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Communicator is already initialized"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setting up cluter\n",
    "setup_objs = start_dask_client()\n",
    "\n",
    "gdf = generate_data(10, mg=True)\n",
    "# create graph\n",
    "g_cu, tcu = create_cu_graph(gdf, mg=True)\n",
    "del gdf\n",
    "\n",
    "# prep\n",
    "deg = g_cu.degree()\n",
    "deg_max = deg['degree'].max().compute()\n",
    "\n",
    "alpha = 1 / deg_max\n",
    "num_nodes = g_cu.number_of_vertices()\n",
    "k = 100 if num_nodes > 100 else num_nodes\n",
    "\n",
    "tc = cu_katz(g_cu, alpha, mg=True)\n",
    "tc = cu_bc(g_cu, k, mg=True)\n",
    "tc = cu_louvain(g_cu, mg=True)\n",
    "tc = cu_tc(g_cu, mg=True)\n",
    "tc = cu_core_num(g_cu, mg=True)\n",
    "tc = cu_pagerank(g_cu, mg=True)\n",
    "tc = cu_jaccard(g_cu, mg=True)\n",
    "tc = cu_bfs(g_cu, mg=True)\n",
    "\n",
    "\n",
    "\n",
    "# Tearing down the cluster\n",
    "stop_dask_client(*setup_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020-2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) \n[GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
